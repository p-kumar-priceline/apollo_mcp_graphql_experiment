Plan for building a recommendation agent

1. **Define Objectives and Success Metrics**
   - Business goals:
     - Identify statistically significant slowdown in profitability from supplier or partner,
       - Create a ML tool that takes in parameters against which it runs a historical model that forecasts the next 7 day of volume/profit. Has to take into account the wider slowdown and how to account for it using BSTS such that it is not throwing out false positives. Use backtesting to ensure the right recommendations are being shown. 
     - identify statistically significant slowdown in volume from supplier or partner,
     - Identify statistically significant lowering in ratio of availability to itinerary creation,
     - Identify leftover inventory at the End of the day and the accompanying margins.
  
   - KPIs for the PoC
     - Number of actionable recommendations.
     - Accuracy.
     - User feedback on whether the identified recommendation is correct or not.

2. **Data Discovery and Access**
   - Relevant data sources in AWS Athena
     - Itinerary data
     - Availability data
     - Change in margins data
   - Set up secure Athena access for the Athena MCP server, ensuring proper permissions and query limits.

  How to use EDA for supporting the progress?
     - Show seasonality of overall demand
     - Show seasonality of overall profit
     - Show seasonality of highest, median and lowest performing supplier
     - Show seasonality of highest, median and lowest performing partner
     - Show the changes in  

1. **MCP Server Setup**
   - Stand up a minimal MCP server (e.g., FastAPI or Flask) to host the agent and expose endpoints.
   - Integrate tools for:
     - Querying Athena (using boto3 or pyathena)
     - Running statistical analyses (e.g., t-tests, A/B test evaluation)
     - Generating visualizations (e.g., matplotlib, seaborn)

2. **Agent Design and Implementation**
   - Implement a modular agent capable of:
     - Define user input or Accepting feedback to refine future recommendations:
       - Add/remove supplier or partner to high priority inspection
       - Add/remove supplier or partner to low priority inspection
       - Reject recommendation thus fine tuning the limits for what would be considered significant difference in booking volume/profitability.
     - Querying and analyzing data from Athena
     - Generating experiment recommendations:
       - Group of partners
       - Supplier
       - Enabling conditions or margin changes??
     - Providing supporting evidence (charts, stats, rationale) that would be generated by MCP server.

3. **Recommendation Logic**
   - Develop initial heuristics or ML models to identify promising experiment opportunities
     - Segments with high variance
     - Under-tested products
   - Implement logic to prioritize recommendations based on impact and feasibility.

4. **User Feedback Loop**
   - Build Streamlit UI for the revenue management team to:
     - Review recommendations
     - Provide feedback (e.g., accept, reject, adjust criteria)
   - Agent memory:
     - Store feedback for iterative improvement.

5. **Testing and Iteration**
   - Test the end-to-end flow with sample data and real users with Promptfoo.
   - Collect feedback and refine data queries, recommendation logic, and user experience.

6. **Documentation and Next Steps**
   - Document architecture, setup, and usage instructions.
   - Outline roadmap for scaling, automation, and integration with production systems.


## Current Approach & Capabilities for Identifying and Prioritizing Pricing Experiments

### 1. Manual, Experience-Driven Process

- **Institutional Knowledge Reliance:**  
  - Experiment selection is guided by domain expertise, historical outcomes, and real-time partner feedback.
  - The team relies on intuition and lessons from prior experiments, especially to identify price-sensitive or responsive partners.

- **Lack of Formal Experimentation Infrastructure:**  
  - No A/B testing framework exists.
  - The team uses "natural" or quasi-controls (e.g., comparing similar partners or before/after periods).

- **Reactive to Business Context and Incidents:**  
  - Pricing system incidents are analyzed retroactively for insights into price sensitivity.
  - Partners who do not react negatively to unintended price increases may be considered for further price adjustments.

- **Incremental Testing When Data is Lacking:**  
  - In the absence of prior data, small, cautious price changes are made and monitored.

- **Overlapping & Unstructured Tracking:**  
  - Test documentation and results are stored in Google Sheets/Docs.
  - Test timing often overlaps, and there is no systematic prioritization, ranking, or filtering beyond manual effort.

- **Partner Collaboration:**  
  - Test prioritization is based on urgency (e.g., partner complaints, mutual price reduction opportunities), business goals, and available team bandwidth.

---

### 2. Capabilities

- Agile and able to quickly react to business needs.
- Deep, direct knowledge of partner behaviors.
- Ability to "mine" incident data and apply learnings.
- Utilizes simple tools (Sheets/Tableau), but processes are manual.

---

### 3. Gaps and Limitations

- No systematic or data-driven scoring/selection.
- No automation for prioritizing across multiple tests or partners.
- Scale and objectivity are limited by manual analysis and individual bandwidth.
- No formal documentation—knowledge is siloed.

---

## Impact of Having an AI Agent for Automated Recommendations

**If an AI Agent Were Available:**

### How an AI Agent Would Transform Experiment Selection and Prioritization

#### 1. Automated, Criteria-Driven Experiment Selection
- The team could specify desired outcomes, partner criteria, and risk preferences.
- The AI would analyze all available data (e.g., historical outcomes, partner sensitivity, seasonality) to recommend the most impactful experiments to run.

#### 2. Efficiency Gains
- AI-driven recommendations would automate much of the manual work.
- No more combing through spreadsheets or relying solely on memory and anecdotal evidence.
- Enables the team to run and evaluate more experiments, faster and in parallel.

#### 3. Improved Effectiveness
- AI could identify overlooked opportunities and optimize prioritization across multiple criteria (e.g., profit impact, learning potential).
- Recommendations would dynamically update as new data arrives.

#### 4. Analytical Rigor & Consistency
- Automated statistical validation (e.g., power calculations, confidence intervals, confounder detection) would make results more robust and transparent.
- Reduces subjective bias and human error.

#### 5. Scalability
- The process would become less dependent on individual knowledge or bandwidth.
- Enables consistent, objective, and repeatable analytics across the entire data set.

#### 6. Codification of Institutional Knowledge
- Domain knowledge and best practices could be encoded into the AI.
- Recommendations would improve over time and be less vulnerable to knowledge loss from team turnover.

---

#### Summary Table

| Area                  | Current State                  | With AI Agent                        |
|-----------------------|-------------------------------|--------------------------------------|
| Experiment Selection  | Manual, intuition-based        | Automated, data-driven               |
| Prioritization        | Ad hoc, bandwidth-limited      | Transparent, scenario-optimized      |
| Analytical Rigor      | Spot checks, informal confidence | Formal validation, deep analytics |
| Speed of Iteration    | Slow, resource-constrained     | Much faster, highly scalable         |
| Documentation/Memory  | Siloed, hard to transfer       | Codified, always improving           |

---

**Summary:**  
The current process is practical and experience-driven, but limited by scalability, objectivity, and efficiency. An AI agent that automates and optimizes experiment selection and prioritization would fundamentally transform the team’s strategic impact and operational speed, making data-driven pricing experimentation a repeatable and scalable business advantage.